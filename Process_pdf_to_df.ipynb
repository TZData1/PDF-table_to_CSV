{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting PDF tables as Pandas Dataframe and save as CSV "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though this script lacks in optimization and efficiency, it was sufficient to fetch and process the data of ~50 PDF-files to CSV, which can finally be used in our supplier database. Potential future work could be integrating selenium to navigate through nested website structures and download desired files. As we already had clear target files, which we needed to process. Furthermore, the last part of the script (automatically writing all tables as CSV-Files in the desired directory) is not done yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tabula\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from selenium import webdriver\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fetch_data():\n",
    "       \n",
    "    def fetch(self, url_beginning, url_list):\n",
    "        ##- 90% of the link stays the same, so we use a list of URL-endings and append it to this constant URL-part\n",
    "        self.urls = []\n",
    "        [self.urls.append(url_beginning + url + \".pdf\") for url in url_list]\n",
    "        ##- Then we download each file using the created links\n",
    "        [urllib.request.urlretrieve(ele, '/Users/thoma/Documents/Roho Network/Development/Data/' + str(i) + \".pdf\") for i, ele in enumerate(self.urls)]\n",
    "    \n",
    "    def read_data(self, directory):\n",
    "        ##- List, which all tables will be appended to. (nested: 1st Level = PDF-file, 2nd Level = Pages within this PDF)\n",
    "        self.data = []\n",
    "        ##- Read all files in directory\n",
    "        for filename in os.listdir(directory):\n",
    "            tables = tabula.read_pdf(\n",
    "                f\"{directory}/{filename}\",\n",
    "                multiple_tables=True,\n",
    "                ##- Read all pages\n",
    "                pages = \"all\")\n",
    "            self.data.append(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##- Initialize fetch_data-Class\n",
    "first = fetch_data()\n",
    "##- URL endings\n",
    "names = [\"Antimicrobial-Wipes\", \"Blood-Pressure-Cuffs\", \"Body-Bags\", \n",
    "         \"Cots\", \"Cotton-Swabs\", \"Disposable-Protective-Apparel\", \"HAZMAT\", \n",
    "         \"Head-Covers\", \"Healthcare-Filtration\", \"Hospital-Bedsheets-and-Pillowcases\", \n",
    "         \"Hospital-Privacy-Curtains\"]\n",
    "##- Use fetch-Function\n",
    "first.fetch(\"http://www.ncto.org/wp-content/uploads/2020/04/COVID-19-FINISHED-GOODS_WEB_\", names)\n",
    "##- Use read_data-Function\n",
    "first.read_data('C:\\\\Users\\\\thoma\\\\Documents\\\\Roho Network\\\\Development\\\\Data\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##- For the first PDF, stack page-table on each others to get one table for one file.\n",
    "tables = []\n",
    "for i in range(len(first.data[0])):\n",
    "    tables.append(first.data[0][i])\n",
    "export_first = pd.concat(tables).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##- Export first dataframe as csv.\n",
    "export_first.to_csv(r\"C:\\Users\\thoma\\Documents\\Roho Network\\Development\\CSVs\\first.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
